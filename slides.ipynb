{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc61d36",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Who: Andrei Olariu\n",
    "## Stone Soup Technology\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "# What: Matching Journalists with Domain Experts\n",
    "## Text Classification with BERT and Gradient Boosting Trees from Idea to Production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a954ba3b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- intro on me and StoneSoup\n",
    "\n",
    "- describing the client and his problem\n",
    "\n",
    "- baseline approach\n",
    "\n",
    "- Machine Learning approach\n",
    "\n",
    "- discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a41beb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<figure style=\"display: table; margin: 0 auto\">\n",
    "  <center>\n",
    "    <img src=\"images/sst.png\" width=\"800vmin\" style=\"padding: 0 0 0 0\">\n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe72eb5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<figure style=\"display: table; margin: 0 auto\">\n",
    "  <center>\n",
    "    <img src=\"images/andrei.jpg\" width=\"1200vmin\" style=\"padding: 4vmin 0 0 0\">\n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d331126",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "that's me during the pandemic\n",
    "\n",
    "phd in natural language processing\n",
    "\n",
    "3 top 10 finishes in kaggle contests\n",
    "\n",
    "at sst, involved in backend, api and ml work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8941c38a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b50b8",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "now you have more context on me and the company I work at\n",
    "\n",
    "unfortunately, I don't know a lot about you, so I had to prepare this workshop making some assumptions\n",
    "\n",
    "if you have experience with something and you find some things trivial, then just breath in, breath out, enjoy the moment and bask in your awesomeness\n",
    "\n",
    "don't wait till the end for questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5a015b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Assumptions\n",
    "\n",
    "- no/little knowledge of Python\n",
    "- no/little experience building and deploying Machine Learning models\n",
    "\n",
    "# Feel free to interrupt me and ask questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afaf41",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<figure style=\"display: table; margin: 0 auto\">\n",
    "  <center>\n",
    "    <img src=\"images/guidedpr.png\" width=\"1200vmin\" style=\"padding: 4vmin 0 0 0\">\n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3270f3e0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have a database of members, with a short description for each\n",
    "\n",
    "<figure style=\"display: table; margin: 0 auto\">\n",
    "  <center>\n",
    "    <img src=\"images/brad.png\" width=\"1200vmin\" style=\"padding: 4vmin 0 0 0\">\n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25de7125",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have new requests coming in from journalists and we want to identify the best matching members\n",
    "\n",
    "<figure style=\"display: table; margin: 0 auto\">\n",
    "  <center>\n",
    "    <img src=\"images/request1.png\" width=\"1200vmin\" style=\"padding: 4vmin 0 0 0\">\n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdc8c58",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What do you think?\n",
    "\n",
    "How can we approach this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8849544e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We need a baseline approach. It needs to be:\n",
    "\n",
    "- easy to implement\n",
    "\n",
    "- easy to explain/understand/debug\n",
    "\n",
    "- predictable\n",
    "\n",
    "- independent of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77091b0f",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Cmon, let's hear some ideas\n",
    "\n",
    "actively thinking about a solution will stimulate the creation of new neural paths inside your brain, making you better problem solvers\n",
    "\n",
    "i swear I'm not moving forward until I get another idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604a3143",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our baseline approach:\n",
    "\n",
    "- index the members' descriptions using a search engine (Solr)\n",
    "\n",
    "- given a request, send it to the search engine as the query and get the highest ranking members\n",
    "\n",
    "- **have a moderator review and correct the matches**\n",
    "\n",
    "- send updated matches to the journalist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cae3c1",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "notice the third step (hard not to)\n",
    "\n",
    "we don't trust the current approach - and it's right so, we haven't evaluated it\n",
    "\n",
    "we are also building a manually annotated dataset to train a ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ddf2ab7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('matches.pickle', 'rb') as f:\n",
    "    matches = pickle.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a705fa2",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "let's load the matches in memory\n",
    "\n",
    "please have a look, try to get a feel of the data we have\n",
    "\n",
    "do a very short exploratory analysis session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e2191eb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39375"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4244665",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'member_id': 113,\n",
       " 'request_id': 28552,\n",
       " 'mismatch': False,\n",
       " 'auto_generated': True}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d71ecf32",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'member_id': 'Andrei',\n",
       " 'request_id': 'Codiax',\n",
       " 'mismatch': True,\n",
       " 'auto_generated': False,\n",
       " 'message': 'remove this from the matches list'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6920e1f5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "matches = matches[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893bb70",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y = [] # the correct labels\n",
    "baseline_predictions = []\n",
    "\n",
    "# write code here...\n",
    "\n",
    "\n",
    "# .. so that the asserts pass\n",
    "assert len(y) == len(baseline_predictions) == len(matches)\n",
    "assert sum(y) == 15739\n",
    "assert sum(baseline_predictions) == 37010"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c513cf",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "write code to build the dataset\n",
    "\n",
    "we'll start with the correct labels for our matches, as well as the baseline predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e015d07",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y = [] # the correct labels\n",
    "baseline_predictions = []\n",
    "\n",
    "# write code here...\n",
    "for match in matches:\n",
    "    if match['auto_generated']:\n",
    "        baseline_predictions.append(1)\n",
    "        if match['mismatch']:\n",
    "            y.append(0)\n",
    "        else:\n",
    "            y.append(1)\n",
    "    else:\n",
    "        baseline_predictions.append(0)\n",
    "        if match['mismatch']:\n",
    "            raise Exception('this is not possible', match)\n",
    "        else:\n",
    "            y.append(1)\n",
    "\n",
    "# .. so that the asserts pass\n",
    "assert len(y) == len(baseline_predictions) == len(matches)\n",
    "assert sum(y) == 15739\n",
    "assert sum(baseline_predictions) == 37010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3bdfaaf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3396911667597907"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = np.array(y)\n",
    "baseline_predictions = np.array(baseline_predictions)\n",
    "\n",
    "sum(baseline_predictions == y) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afe4251",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "let's compute the accuracy of our baseline approach\n",
    "\n",
    "is this a good score or a bad score?\n",
    "\n",
    "if doing pedestrian detection for autonomous driving, probably a bad score\n",
    "\n",
    "but if you search for something on google and 3 of the first 10 results are what you were looking for, then it's probably a good score\n",
    "\n",
    "in our case, we can ask for feedback from the moderators, since they're the ones that see these results\n",
    "\n",
    "apart from that, for us this is just a number out of context\n",
    "\n",
    "it will prove useful further on, as we can evaluate new models and improvements and compare them to existing models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd2de02",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Word2vec\n",
    "\n",
    "<figure style=\"display: table; margin: 0 auto\">\n",
    "  <center>\n",
    "    <img src=\"images/word2vec.png\" width=\"1200vmin\" style=\"padding: 4vmin 0 0 0\">\n",
    "  </center>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec717b4",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "technique for computing word embeddings - represent words as arrays\n",
    "\n",
    "underneath, a neural network that would see a lot of phrases\n",
    "\n",
    "the resulting arrays would show some interesting properties and relationships between words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd9951",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<figure style=\"display: table; margin: 0 auto\">\n",
    "  <center>\n",
    "    <img src=\"images/word2vec2.svg\" width=\"1300vmin\" style=\"padding: 4vmin 0 0 0\">\n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb973d",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "king - man + woman ~= queen\n",
    "\n",
    "very interesting technique, lots of applications, but not a breakthrough as what was happening at the time with neural networks on images, where pretrained neural networks were being used everywhere\n",
    "\n",
    "that breakthrough came though in 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951f4fd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<figure style=\"display: table; margin: 0 auto\">\n",
    "  <center>\n",
    "    <img src=\"images/bert2.jpg\" width=\"1200vmin\" style=\"padding: 4vmin 0 0 0\">\n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57369630",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "we're no longer working with word embeddings, but with sentence embeddings\n",
    "\n",
    "these new models are trained on huge datasets and then shared, so you can use them out of the box or fine tune them on your small dataset\n",
    "\n",
    "they revolutionized the field of NLP and led to significant improvements on most problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee7359",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<figure style=\"display: table; margin: 0 auto\">\n",
    "  <center>\n",
    "    <img src=\"images/bert.png\" width=\"1000vmin\" style=\"padding: 4vmin 0 0 0\">\n",
    "  </center>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3c16d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Install\n",
    "\n",
    "```bash\n",
    "pip install bert-serving-server  # server\n",
    "pip install bert-serving-client  # client, independent of `bert-serving-server`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2768fe",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "the server loads the pretrained network in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52893165",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 768)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_serving.client import BertClient\n",
    "\n",
    "bc = BertClient()\n",
    "results = bc.encode(['Lion is the king of the jungle',\n",
    "    'The tiger hunts in this forest',\n",
    "    'Everybody loves New York'])\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7cc367",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "you can see the embeddings for the first two sentences are more alligned when compared to the third sentence\n",
    "\n",
    "we can't share the dataset with the request content and member descriptions, but we can share the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dc0f860",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18777914\n",
      "0.13391979\n",
      "0.12317723\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(results[0] * results[1]))\n",
    "print(np.mean(results[0] * results[2]))\n",
    "print(np.mean(results[1] * results[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17aeaaad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "with open('embeddings.pickle', 'rb') as f:\n",
    "  member_embeddings, request_embeddings = pickle.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f9f730d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = []\n",
    "for match in matches:\n",
    "    X.append(member_embeddings[match['member_id']] * \\\n",
    "        request_embeddings[match['request_id']])\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test, _, baseline_predictions_test = \\\n",
    "    train_test_split(X, y, baseline_predictions, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5855197e",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "now that we have a training dataset, let's try to plug it into an algorithm and get some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a22dd32d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37405, 768)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "582586b1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1969, 768)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa0c834",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<figure style=\"display: table; margin: 0 auto\">\n",
    "  <center>\n",
    "    <img src=\"images/titanic.jpg\" width=\"600vmin\" style=\"padding: 4vmin 0 0 0\">\n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c0604",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<figure style=\"display: table; margin: 0 auto\">\n",
    "  <center>\n",
    "    <img src=\"images/forest.png\" width=\"700vmin\" style=\"padding: 4vmin 0 0 0\">\n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3fefe0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<figure style=\"display: table; margin: 0 auto\">\n",
    "  <center>\n",
    "    <img src=\"images/gbt.png\" width=\"1200vmin\" style=\"padding: 4vmin 0 0 0\">\n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d2ee9d7d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_v1 = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='auc',\n",
    "    gpu_id=0, #GPU enabled\n",
    "    tree_method='gpu_hist',\n",
    ")\n",
    "model_v1.fit(X_train, y_train)\n",
    "model_v1_predictions = model_v1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "81718c72",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline: 0.3484002031488065\n",
      "new model: 0.8207211782630777\n"
     ]
    }
   ],
   "source": [
    "print('baseline:', sum(baseline_predictions_test == y_test)/len(y_test))\n",
    "print('new model:', sum(model_v1_predictions == y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd9b19b",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "we're using accuracy\n",
    "\n",
    "great results\n",
    "\n",
    "job done, go home and feel happy about it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00c1eae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<figure style=\"display: table; margin: 0 auto\">\n",
    "  <center>\n",
    "    <img src=\"images/acc.png\" width=\"700vmin\" style=\"padding: 4vmin 0 0 0\">\n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63319e58",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "does anybody feel we might be missing something here?\n",
    "\n",
    "this formula for accuracy is the general one; for binary classification we have the equivalent, but slightly more detailed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc70a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<figure style=\"display: table; margin: 0 auto\">\n",
    "  <center>\n",
    "    <img src=\"images/acc2.png\" width=\"700vmin\" style=\"padding: 4vmin 0 0 0\">\n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "<figure style=\"display: table; margin: 0 auto\">\n",
    "  <center>\n",
    "    <img src=\"images/confusion-matrix.png\" width=\"800vmin\" style=\"padding: 4vmin 0 0 0\">\n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e9b038",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "did anybody figure out where i'm going with this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936d3c27",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<figure style=\"display: table; margin: 0 auto\">\n",
    "  <center>\n",
    "    <img src=\"images/acc2.png\" width=\"700vmin\" style=\"padding: 4vmin 0 0 0\">\n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "<figure style=\"display: table; margin: 0 auto\">\n",
    "  <center>\n",
    "    <img src=\"images/confusion-matrix2.png\" width=\"800vmin\" style=\"padding: 4vmin 0 0 0\">\n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81ef1af",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "so it seems like we have no true negatives in our dataset\n",
    "\n",
    "let's say we have 100 members and the algorithm only returns 5 matches; let's say the moderator adds another 5 members to the results; the remaining 90 members are the true negatives; both the algorithm and the human moderator haven't selected them; but they are not in our dataset\n",
    "\n",
    "we need to add true negatives to our dataset:\n",
    "- for a better understanding of our algorithm's performance\n",
    "- for training a better ML model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a05658",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "EXTEND_COUNT = 120000\n",
    "# list of dictionaries {'member_id': int, 'request_id': int}\n",
    "true_negatives = []\n",
    "\n",
    "# generate 120000 random new matches ...\n",
    "\n",
    "\n",
    "# ... such that these tests pass\n",
    "assert len(true_negatives) == EXTEND_COUNT\n",
    "true_negatives_set = {(tn['member_id'], tn['request_id']) for tn in true_negatives}\n",
    "assert len(true_negatives_set) == EXTEND_COUNT\n",
    "\n",
    "old_matches_set = {(d['member_id'], d['request_id']) for d in matches}\n",
    "member_ids_set = {d['member_id'] for d in matches}\n",
    "request_ids_set = {d['request_id'] for d in matches}\n",
    "\n",
    "assert len(true_negatives_set.difference(old_matches_set)) == EXTEND_COUNT\n",
    "for tn in true_negatives:\n",
    "    assert tn['member_id'] in member_ids_set\n",
    "    assert tn['request_id'] in request_ids_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eff3495a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "EXTEND_COUNT = 120000\n",
    "# list of dictionaries {'member_id': int, 'request_id': int}\n",
    "true_negatives = []\n",
    "\n",
    "# generate 120000 random new matches ...\n",
    "import random\n",
    "\n",
    "member_ids = list({d['member_id'] for d in matches})\n",
    "request_ids = list({d['request_id'] for d in matches})\n",
    "all_matches_set = {(d['member_id'], d['request_id']) for d in matches}\n",
    "\n",
    "while True:\n",
    "  member_id = member_ids[random.randint(0, len(member_ids) - 1)]\n",
    "  request_id = request_ids[random.randint(0, len(request_ids) - 1)]\n",
    "  if (member_id, request_id) in all_matches_set:\n",
    "    continue\n",
    "  true_negatives.append({\n",
    "      'member_id': member_id,\n",
    "      'request_id': request_id,\n",
    "  })\n",
    "  all_matches_set.add((member_id, request_id))\n",
    "\n",
    "  if len(true_negatives) == EXTEND_COUNT:\n",
    "    break\n",
    "\n",
    "# ... such that these tests pass\n",
    "assert len(true_negatives) == EXTEND_COUNT\n",
    "true_negatives_set = {(tn['member_id'], tn['request_id']) for tn in true_negatives}\n",
    "assert len(true_negatives_set) == EXTEND_COUNT\n",
    "\n",
    "old_matches_set = {(d['member_id'], d['request_id']) for d in matches}\n",
    "member_ids_set = {d['member_id'] for d in matches}\n",
    "request_ids_set = {d['request_id'] for d in matches}\n",
    "\n",
    "assert len(true_negatives_set.difference(old_matches_set)) == EXTEND_COUNT\n",
    "for tn in true_negatives:\n",
    "    assert tn['member_id'] in member_ids_set\n",
    "    assert tn['request_id'] in request_ids_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51e691f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_tn = []\n",
    "y_tn = []\n",
    "baseline_predictions_tn = []\n",
    "\n",
    "# generate a dataset solely for these new true negatives...\n",
    "\n",
    "\n",
    "# .. so that the asserts pass\n",
    "assert len(X_tn) == len(y_tn) == len(baseline_predictions_tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de8eb046",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_tn = []\n",
    "y_tn = []\n",
    "baseline_predictions_tn = []\n",
    "\n",
    "# generate a dataset solely for these new true negatives...\n",
    "for match in true_negatives:\n",
    "    X_tn.append(member_embeddings[match['member_id']] * \\\n",
    "        request_embeddings[match['request_id']])\n",
    "    y_tn.append(0)\n",
    "    baseline_predictions_tn.append(0)\n",
    "\n",
    "# .. so that the assert passes\n",
    "assert len(X_tn) == len(y_tn) == len(baseline_predictions_tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b349443",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# split this new dataset into train and test...\n",
    "\n",
    "# ... then extend the previous dataset...\n",
    "\n",
    "# ... so that the asserts pass\n",
    "assert X_train_extended.shape == (151405, 768)\n",
    "assert X_test_extended.shape == (7969, 768)\n",
    "assert len(y_train_extended) == 151405\n",
    "assert len(y_test_extended) == 7969\n",
    "assert len(baseline_predictions_test_extended) == 7969\n",
    "assert sum(y_train_extended) == 14913\n",
    "assert sum(y_test_extended) == 826\n",
    "assert sum(baseline_predictions_test_extended) == 1829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "324852a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# split this new dataset into train and test...\n",
    "X_train_tn, X_test_tn, y_train_tn, y_test_tn, _, baseline_predictions_test_tn = \\\n",
    "    train_test_split(X_tn, y_tn, baseline_predictions_tn, test_size=0.05, random_state=42)\n",
    "\n",
    "# ... then extend the previous dataset...\n",
    "X_train_extended = np.vstack((X_train, X_train_tn))\n",
    "X_test_extended = np.vstack((X_test, X_test_tn))\n",
    "y_train_extended = np.hstack((y_train, y_train_tn))\n",
    "y_test_extended = np.hstack((y_test, y_test_tn))\n",
    "baseline_predictions_test_extended = np.hstack((baseline_predictions_test, baseline_predictions_test_tn))\n",
    "\n",
    "# ... so that the asserts pass\n",
    "assert X_train_extended.shape == (151405, 768)\n",
    "assert X_test_extended.shape == (7969, 768)\n",
    "assert len(y_train_extended) == 151405\n",
    "assert len(y_test_extended) == 7969\n",
    "assert len(baseline_predictions_test_extended) == 7969\n",
    "assert sum(y_train_extended) == 14913\n",
    "assert sum(y_test_extended) == 826\n",
    "assert sum(baseline_predictions_test_extended) == 1829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d97b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_v2 = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='auc',\n",
    "    gpu_id=0, #GPU enabled\n",
    "    tree_method='gpu_hist',\n",
    ")\n",
    "model_v2.fit(X_train_extended, y_train_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ddee43c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline: 0.8390011293763333\n",
      "model v1: 0.6987074915296775\n",
      "model v2: 0.9116576734847535\n"
     ]
    }
   ],
   "source": [
    "model_v1_predictions = model_v1.predict(X_test_extended)\n",
    "model_v2_predictions = model_v2.predict(X_test_extended)\n",
    "\n",
    "print('baseline:', sum(baseline_predictions_test_extended == y_test_extended)/len(y_test_extended))\n",
    "print('model v1:', sum(model_v1_predictions == y_test_extended)/len(y_test_extended))\n",
    "print('model v2:', sum(model_v2_predictions == y_test_extended)/len(y_test_extended))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9786b1b",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "we've been using accuracy, since we've approached this as a classification problem are we're working with classification models\n",
    "\n",
    "but this is more of a ranking problem, so we should evaluate it accordingly\n",
    "\n",
    "for example, when working with accuracy, each trained model needs a threshold that separates the two labels; usually 0.5\n",
    "\n",
    "but for ranking, there is no such threshold; instead items are assigned a score by the model and then ranked based on the score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d053385",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<figure style=\"display: table; margin: 0 auto\">\n",
    "  <center>\n",
    "    <img src=\"images/roc.jpg\" width=\"900vmin\" style=\"padding: 4vmin 0 0 0\">\n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7dc8a9",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "let's look at this chart\n",
    "\n",
    "i'm not going to explain it from a theoretical perspective - i don't think i'll do a good job\n",
    "\n",
    "i'll just talk about interpreting it visually\n",
    "\n",
    "the blue line on the diagonal is how a worthless model would look like - using a coin toss to see if matches are good\n",
    "\n",
    "the better a model is, the more it will lean towards the upper left\n",
    "\n",
    "can we have something towards the lower right? yes, a model that outputs the opposite of a good prediction; but you can just reverse it and get a good prediction, so in practice there's nothing below the diagonal\n",
    "\n",
    "the metric we'll be using is called AUC - area under curve; and it's exactly that; worthless gets 0.5, perfect gets 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a0365507",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9\n",
      "auc: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
    "predictions = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "print('accuracy:', sum(predictions == y)/len(y))\n",
    "print('auc:', metrics.roc_auc_score(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802c1c2d",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "when comparing accuracy with auc, there are 2 big things to consider\n",
    "\n",
    "first is performance on unbalanced datasets\n",
    "\n",
    "imagine a covid test that always says you don't have the virus; if you apply the test to 100 people and only one has the virus, the accuracy of the test will be 99%, which 99% of the people will say is very good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8c7f0613",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 1.0\n"
     ]
    }
   ],
   "source": [
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
    "predictions = np.array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2])\n",
    "print('auc:', metrics.roc_auc_score(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209a02b",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "second difference - auc doesn't need 0s and 1s, it works with values inbetween; this is great if you're interested in the confidence or probability of a result; also great for ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f704c0bb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline: 0.8352458374561322\n",
      "model v1: 0.7896102247446577\n",
      "model v2: 0.9018669626607467\n"
     ]
    }
   ],
   "source": [
    "model_v1_predictions = model_v1.predict_proba(X_test_extended)[:,1]\n",
    "model_v2_predictions = model_v2.predict_proba(X_test_extended)[:,1]\n",
    "\n",
    "print('baseline:', metrics.roc_auc_score(y_test_extended, baseline_predictions_test_extended))\n",
    "print('model v1:', metrics.roc_auc_score(y_test_extended, model_v1_predictions))\n",
    "print('model v2:', metrics.roc_auc_score(y_test_extended, model_v2_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f09443",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Epilogue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e202fe",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- the model has been in production for 2 years\n",
    "- there were some questions in the beginning as to why someone was matched or someone wasn't matched; usually you can figure out from the text what's happening\n",
    "- a year ago, the manual review step was removed, so matches are now being sent directly to members, asking them to comment on the request\n",
    "- no other complaints since then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278a4388",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What can we improve?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf427ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
